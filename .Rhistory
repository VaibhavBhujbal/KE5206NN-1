demo()
demo(plotmath)
install.packages("rattle")
library(rattle)
install.packages("rattle")
install.packages("rattle", dependencies = T)
install.packages("rattle", dependencies = T)
install.packages("RGtk2", depen=T)
install.packages("RGtk2", depen=T)
install.packages("RGtk2", depen=T)
install.packages("RGtk2", depen=T)
install.packages("Cairo Device")
install.packages("RGtk2")
R CMD INSTALL ~/Downloads/RGtk2_version.tar.gz
package.install('RGtk2')
install.packages("RGtk2")
install.packages("RGtk2")
install.packages("rattle", dependencies = T)
install.packages("rattle")
install.packages("RGtk2")
install.packages("RGtk2")
install.packages("https://togaware.com/access/rattle_5.0.14.tar.gz", repos=NULL, type="source")
install.packages("https://togaware.com/access/rattle_5.0.14.tar.gz", repos=NULL, type="source")
install.packages("RGtk2")
install.packages("RGtk2")
library(rattle)
rattle()
library(rattle)
rattle()
install.packages(X11)
install.packages("RGtk2")
library(rattle)
rattle()
rattle()
library(rattle)
rattle()
library(rattle)
rattle()
library(RGtk2)
library(rattle)
rattle()
library(rattle)
rattle()
library(rattle)
rattle()
rattle()
library(rattle)
rattle()
library(nnet)
library(Metrics)
setwd('/Users/pierlim/R_Projects/KE5206NN')
train_df <- read.csv('fields_removed.csv')
test_df <- read.csv('test_fields_removed.csv')
# min max normalisation
max_share_val <- max(train_df$shares)
min_share_val <- min(train_df$shares)
maxs = apply(train_df, 2, max)
mins = apply(train_df, 2 ,min)
shares = as.numeric(train_df$shares)
train_scaled_df <- as.data.frame(scale(train_df, center = mins, scale = maxs - mins))
# scale test data using train data's params
test_scaled_df <- as.data.frame(scale(test_df, center = mins, scale = maxs - mins))
# fn to convert from normalized to actual share value
get_num_shares <- function(share_norm, min_share_val, max_share_val) {
return (share_norm * (max_share_val - min_share_val) + min_share_val)
}
max_size <- 3
best_rmse <- 999.0
best_rbf_model <- NA
for (i in 2:max_size) {
print(i)
rbf_model <- rbf(nn_df, nn_df$shares, size=i, linOut=TRUE)
print("aftermodel")
rbf_predict <- predict(rbf_model, nn_test_df)
print("afterpredict")
rmse_result <- rmse(nn_test_df$shares, rbf_predict)
if (rmse_result < best_rmse) {
best_rmse <- rmse_result
best_rbf_model <- rbf_model
print("found")
}
}
library(RSNNS)
nn_df <- train_scaled_df
nn_test_df <- test_scaled_df
set.seed(42)
max_size <- 3
best_rmse <- 999.0
best_rbf_model <- NA
for (i in 2:max_size) {
print(i)
rbf_model <- rbf(nn_df, nn_df$shares, size=i, linOut=TRUE)
print("aftermodel")
rbf_predict <- predict(rbf_model, nn_test_df)
print("afterpredict")
rmse_result <- rmse(nn_test_df$shares, rbf_predict)
if (rmse_result < best_rmse) {
best_rmse <- rmse_result
best_rbf_model <- rbf_model
print("found")
}
}
max_size <- 10
best_rmse <- 999.0
best_rbf_model <- NA
for (i in 2:max_size) {
print(i)
rbf_model <- rbf(nn_df, nn_df$shares, size=i, linOut=TRUE)
print("aftermodel")
rbf_predict <- predict(rbf_model, nn_test_df)
print("afterpredict")
rmse_result <- rmse(nn_test_df$shares, rbf_predict)
if (rmse_result < best_rmse) {
best_rmse <- rmse_result
best_rbf_model <- rbf_model
print("found")
}
}
View(best_rbf_model)
max_size <- 50
best_rmse <- 999.0
best_rbf_model <- NA
for (i in 2:max_size) {   # putting size=1 will crash rbf
rbf_model <- rbf(nn_df, nn_df$shares, size=i, linOut=TRUE)
rbf_predict <- predict(rbf_model, nn_test_df)
rmse_result <- rmse(nn_test_df$shares, rbf_predict)
if (rmse_result < best_rmse) {
best_rmse <- rmse_result
best_rbf_model <- rbf_model
cat("best size param = " + i)
}
}
max_size <- 50
best_rmse <- 999.0
best_rbf_model <- NA
for (i in 2:max_size) {   # putting size=1 will crash rbf
rbf_model <- rbf(nn_df, nn_df$shares, size=i, linOut=TRUE)
rbf_predict <- predict(rbf_model, nn_test_df)
rmse_result <- rmse(nn_test_df$shares, rbf_predict)
if (rmse_result < best_rmse) {
best_rmse <- rmse_result
best_rbf_model <- rbf_model
cat("best size param = ", i)
}
}
rbf_model <- rbf(nn_df, nn_df$shares, size=46, linOut=TRUE)
rbf_predict <- predict(rbf_model, nn_test_df)
rmse_result <- rmse(nn_test_df$shares, rbf_predict)
print("RBF Model RMSE:")
print(rmse_result)
View(rbf_predict)
View(rbf_predict)
rbf_predict <- predict(rbf_model, nn_df)
rmse_result <- rmse(nn_df$shares, rbf_predict)
print("RBF Model RMSE:")
print(rmse_result)
library(grnn)
library(doSNOW)
library(doParallel)
nn_df <- train_scaled_df
nn_test_df <- test_scaled_df
grnn <- smooth(learn(nn_df, variable.column = ncol(nn_df)), sigma=0.2)
pred <- pred_grnn(nn_test_df[1:10], grnn) # runs forever
pred_grnn <- function(x, nn){
xlst <- split(x, 1:nrow(x))
pred <- foreach(i = xlst, .combine = rbind) %dopar% {
data.frame(pred = guess(nn, as.matrix(i)), i, row.names = NULL)
}
}
library(grnn)
library(doSNOW)
library(doParallel)
nn_df <- train_scaled_df
nn_test_df <- test_scaled_df
grnn <- smooth(learn(nn_df, variable.column = ncol(nn_df)), sigma=0.2)
pred <- pred_grnn(nn_test_df[1:10], grnn) # runs forever
rmse_result <- rmse(nn_df$shares, pred)
print("GRNN Model RMSE:")
print(rmse_result)
nn_df <- train_scaled_df
nn_test_df <- test_scaled_df
grnn <- smooth(learn(nn_df, variable.column = ncol(nn_df)), sigma=0.2)
pred <- pred_grnn(nn_test_df[1:100], grnn) # runs forever
pred_shares <-  pred * (max_share_val - min_share_val) + min_share_val
actual_shares <- (nn_df$shares * (max_share_val - min_share_val)) + min_share_val
rmse_result <- rmse(nn_df$shares, pred)
print("GRNN Model RMSE:")
print(rmse_result)
library(grnn)
library(doSNOW)
library(doParallel)
nn_df <- train_scaled_df
nn_test_df <- test_scaled_df
grnn <- smooth(learn(nn_df, variable.column = ncol(nn_df)), sigma=0.2)
pred <- pred_grnn(nn_test_df[1:100], grnn) # runs forever
library(grnn)
library(doSNOW)
library(doParallel)
nn_df <- train_scaled_df
nn_test_df <- test_scaled_df
grnn <- smooth(learn(nn_df, variable.column = ncol(nn_df)), sigma=0.2)
pred <- pred_grnn(nn_test_df[1:100,], grnn) # runs forever
# random search
activation_opt <- c("Rectifier", "Maxout", "Tanh")
l1_opt <- c(0, 0.00001, 0.0001, 0.001, 0.01)
l2_opt <- c(0, 0.00001, 0.0001, 0.001, 0.01)
hyper_params <- list(activation = activation_opt, l1 = l1_opt, l2 = l2_opt)
search_criteria <- list(strategy = "RandomDiscrete", max_runtime_secs = 600)
splits <- h2o.splitFrame(as.h2o(nn_df), ratios = 0.8, seed = 1)
dl_grid <- h2o.grid("deeplearning", x = x, y = y,
grid_id = "dl_grid",
training_frame = splits[[1]],
validation_frame = splits[[2]],
seed = 1,
hidden = c(100,100,50),
hyper_params = hyper_params,
search_criteria = search_criteria)
dl_gridperf <- h2o.getGrid(grid_id = "dl_grid",
sort_by = "rmse",
decreasing = TRUE)
print(dl_gridperf)
activation_opt <- c("Rectifier", "Maxout", "Tanh")
l1_opt <- c(0, 0.00001, 0.0001, 0.001, 0.01)
l2_opt <- c(0, 0.00001, 0.0001, 0.001, 0.01)
hyper_params <- list(activation = activation_opt, l1 = l1_opt, l2 = l2_opt)
search_criteria <- list(strategy = "RandomDiscrete", max_runtime_secs = 600)
splits <- h2o.splitFrame(as.h2o(nn_df), ratios = 0.8, seed = 1)
splits <- h2o.splitFrame(nn_df, ratios = 0.8, seed = 1)
h2o.splitFrame(nn_df, ratios=0.8)
dl_grid <- h2o.grid("deeplearning", x = x, y = y,
grid_id = "dl_grid",
training_frame = as.h2o(nn_df),
validation_frame = as.h2o(nn_test_df),
seed = 1,
hidden = c(100,100,50),
hyper_params = hyper_params,
search_criteria = search_criteria)
library(h2o)
dl_grid <- h2o.grid("deeplearning", x = x, y = y,
grid_id = "dl_grid",
training_frame = as.h2o(nn_df),
validation_frame = as.h2o(nn_test_df),
seed = 1,
hidden = c(100,100,50),
hyper_params = hyper_params,
search_criteria = search_criteria)
splits <- h2o.splitFrame(as.h2o(nn_df), ratios = 0.8, seed = 1)
h2o.init()
splits <- h2o.splitFrame(as.h2o(nn_df), ratios = 0.8, seed = 1)
dl_grid <- h2o.grid("deeplearning", x = x, y = y,
grid_id = "dl_grid",
training_frame = splits[[1]],
validation_frame = splits[[2]],
seed = 1,
hidden = c(100,100,50),
hyper_params = hyper_params,
search_criteria = search_criteria)
splits <- h2o.splitFrame(as.h2o(nn_df), ratios = 0.8, seed = 1)
dl_grid <- h2o.grid("deeplearning", x = names(h20_df),
y = "shares",
grid_id = "dl_grid",
training_frame = splits[[1]],
validation_frame = splits[[2]],
seed = 1,
hidden = c(100,100,50),
hyper_params = hyper_params,
search_criteria = search_criteria)
h20_df <- nn_df[ , -which(names(nn_df) %in% c("shares"))]
activation_opt <- c("Rectifier", "Maxout", "Tanh")
l1_opt <- c(0, 0.00001, 0.0001, 0.001, 0.01)
l2_opt <- c(0, 0.00001, 0.0001, 0.001, 0.01)
hyper_params <- list(activation = activation_opt, l1 = l1_opt, l2 = l2_opt)
search_criteria <- list(strategy = "RandomDiscrete", max_runtime_secs = 600)
splits <- h2o.splitFrame(as.h2o(nn_df), ratios = 0.8, seed = 1)
dl_grid <- h2o.grid("deeplearning", x = names(h20_df),
y = "shares",
grid_id = "dl_grid",
training_frame = splits[[1]],
validation_frame = splits[[2]],
seed = 1,
hidden = c(100,100,50),
hyper_params = hyper_params,
search_criteria = search_criteria)
dl_gridperf <- h2o.getGrid(grid_id = "dl_grid",
sort_by = "rmse",
decreasing = TRUE)
print(dl_gridperf)
dl_gridperf <- h2o.getGrid(grid_id = "dl_grid",
sort_by = "rmse",
decreasing = FALSE)
print(dl_gridperf)
nn_df <- train_scaled_df
nn_test_df <- test_scaled_df
h20_df <- nn_df[ , -which(names(nn_df) %in% c("shares"))]
dl_fit1 <- h2o.deeplearning(x = names(h20_df),
y = "shares",
training_frame = as.h2o(nn_df),
model_id = "dl_fit1",
hidden = c(100, 100, 50),
nfolds = 3,
seed = 1, epochs = 10000, l1=1e-5, l2=1e-5, activation = "Maxout")
h2o_predict <- as.data.frame(h2o.predict(dl_fit1, as.h2o(nn_test_df)))
pred_shares <- get_num_shares(h2o_predict, min_share_val, max_share_val)
actual_shares <- get_num_shares(nn_test_df$shares, min_share_val, max_share_val)
print("RMSE for neural network is :")
print(rmse(nn_test_df$shares, h2o_predict))
print("Training RMSE:")
print(h2o.rmse(dl_fit1))
plot(dl_fit1, timestep = "epochs", metric = "rmse")
h2o.init()
# random search
activation_opt <- c("Rectifier", "Maxout", "Tanh", "RectifierWithDropout", "TanhWithDropout", "MaxoutWithDropout")
l1_opt <- c(0, 0.00001, 0.0001, 0.001, 0.01)
l2_opt <- c(0, 0.00001, 0.0001, 0.001, 0.01)
hyper_params <- list(activation = activation_opt, l1 = l1_opt, l2 = l2_opt)
#search_criteria <- list(strategy = "RandomDiscrete", max_runtime_secs = 600)
search_criteria <- list(strategy = "Cartesian", max_runtime_secs = 600)
splits <- h2o.splitFrame(as.h2o(nn_df), ratios = 0.8, seed = 1)
dl_grid <- h2o.grid("deeplearning", x = names(h20_df),
y = "shares",
grid_id = "dl_grid",
training_frame = splits[[1]],
validation_frame = splits[[2]],
seed = 1,
hidden = c(100,100,50),
hyper_params = hyper_params,
search_criteria = search_criteria)
dl_gridperf <- h2o.getGrid(grid_id = "dl_grid",
sort_by = "rmse",
decreasing = FALSE)
print(dl_gridperf)
rm(list=ls())
library(nnet)
library(Metrics)
setwd('/Users/pierlim/R_Projects/KE5206NN')
train_df <- read.csv('fields_removed.csv')
test_df <- read.csv('test_fields_removed.csv')
# min max normalisation
max_share_val <- max(train_df$shares)
min_share_val <- min(train_df$shares)
maxs = apply(train_df, 2, max)
mins = apply(train_df, 2 ,min)
shares = as.numeric(train_df$shares)
train_scaled_df <- as.data.frame(scale(train_df, center = mins, scale = maxs - mins))
# scale test data using train data's params
test_scaled_df <- as.data.frame(scale(test_df, center = mins, scale = maxs - mins))
# fn to convert from normalized to actual share value
get_num_shares <- function(share_norm, min_share_val, max_share_val) {
return (share_norm * (max_share_val - min_share_val) + min_share_val)
}
library(h2o)
nn_df <- train_scaled_df
nn_test_df <- test_scaled_df
h20_df <- nn_df[ , -which(names(nn_df) %in% c("shares"))]
h2o.init()
# random search
activation_opt <- c("Rectifier", "Maxout", "Tanh", "RectifierWithDropout", "TanhWithDropout", "MaxoutWithDropout")
l1_opt <- c(0, 0.00001, 0.0001, 0.001, 0.01)
l2_opt <- c(0, 0.00001, 0.0001, 0.001, 0.01)
hyper_params <- list(activation = activation_opt, l1 = l1_opt, l2 = l2_opt)
#search_criteria <- list(strategy = "RandomDiscrete", max_runtime_secs = 600)
search_criteria <- list(strategy = "Cartesian", max_runtime_secs = 600)
splits <- h2o.splitFrame(as.h2o(nn_df), ratios = 0.8, seed = 1)
dl_grid <- h2o.grid("deeplearning", x = names(h20_df),
y = "shares",
grid_id = "dl_grid",
training_frame = splits[[1]],
validation_frame = splits[[2]],
seed = 1,
hidden = c(100,100,50),
hyper_params = hyper_params,
search_criteria = search_criteria)
dl_gridperf <- h2o.getGrid(grid_id = "dl_grid",
sort_by = "rmse",
decreasing = FALSE)
print(dl_gridperf)
h2o.shutdown
h2o.shutdown()
h2o.init()
# random search
activation_opt <- c("Rectifier", "Maxout", "Tanh", "RectifierWithDropout", "TanhWithDropout", "MaxoutWithDropout")
l1_opt <- c(0, 0.00001, 0.0001, 0.001, 0.01)
l2_opt <- c(0, 0.00001, 0.0001, 0.001, 0.01)
hyper_params <- list(activation = activation_opt, l1 = l1_opt, l2 = l2_opt)
#search_criteria <- list(strategy = "RandomDiscrete", max_runtime_secs = 600)
search_criteria <- list(strategy = "Cartesian", max_runtime_secs = 600)
splits <- h2o.splitFrame(as.h2o(nn_df), ratios = 0.8, seed = 1)
dl_grid <- h2o.grid("deeplearning", x = names(h20_df),
y = "shares",
grid_id = "dl_grid",
training_frame = splits[[1]],
validation_frame = splits[[2]],
seed = 1,
hidden = c(100,100,50),
hyper_params = hyper_params,
search_criteria = search_criteria)
dl_gridperf <- h2o.getGrid(grid_id = "dl_grid",
sort_by = "rmse",
decreasing = FALSE)
print(dl_gridperf)
