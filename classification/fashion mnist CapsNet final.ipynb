{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "dec05004-ccb3-490e-b588-27c0f4f06d1e",
    "_uuid": "41907ec74cae883fa8d56f6556cade5c67c8f3e0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lam/anaconda2/envs/tf15/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train = pd.read_csv('input/fashion-mnist_train.csv')\n",
    "data_test = pd.read_csv('input/fashion-mnist_test.csv')\n",
    "\n",
    "batch_size = 100\n",
    "num_classes = 10\n",
    "# epochs = 40\n",
    "epochs = 15\n",
    "\n",
    "img_rows, img_cols = 28, 28\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "X = np.array(data_train.iloc[:, 1:])\n",
    "y = to_categorical(np.array(data_train.iloc[:, 0]))\n",
    "\n",
    "#Here we split validation data to optimiza classifier during training\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=13)\n",
    "\n",
    "#Test data\n",
    "X_test = np.array(data_test.iloc[:, 1:])\n",
    "y_test = to_categorical(np.array(data_test.iloc[:, 0]))\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "X_val = X_val.reshape(X_val.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_val = X_val.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "X_val /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imgaug import augmenters as iaa\n",
    "\n",
    "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "# seq = iaa.Sequential([iaa.Fliplr(0.5), sometimes(iaa.Affine(rotate=(-5, 5), shear=(-5, 5)))])\n",
    "seq = iaa.Sequential([iaa.Fliplr(0.5)])\n",
    "X_train = seq.augment_images(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "0599166d-b975-4c88-8b91-071a8f4fb0cd",
    "_uuid": "0e9db73157e2c0e481bf3d73892d8d29263aa56f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras import layers, models, optimizers\n",
    "from keras import backend as K\n",
    "from capsulelayers import CapsuleLayer, PrimaryCap, Length, Mask\n",
    "\n",
    "K.set_image_data_format('channels_last')\n",
    "\n",
    "x = layers.Input(shape=input_shape)\n",
    "\n",
    "# Layer 1: Just a conventional Conv2D layer\n",
    "conv1 = layers.Conv2D(filters=256, kernel_size=9, strides=1, padding='valid', activation='relu', name='conv1')(x)\n",
    "\n",
    "# Layer 2: Conv2D layer with `squash` activation, then reshape to [None, num_capsule, dim_capsule]\n",
    "primarycaps = PrimaryCap(conv1, dim_capsule=8, n_channels=32, kernel_size=9, strides=2, padding='valid')\n",
    "\n",
    "# Layer 3: Capsule layer. Routing algorithm works here.\n",
    "digitcaps = CapsuleLayer(num_capsule=num_classes, dim_capsule=16, num_routing=3,\n",
    "                         name='digitcaps')(primarycaps)\n",
    "\n",
    "# Layer 4: This is an auxiliary layer to replace each capsule with its length. Just to match the true label's shape.\n",
    "# If using tensorflow, this will not be necessary. :)\n",
    "out_caps = Length(name='capsnet')(digitcaps)\n",
    "\n",
    "# Decoder network.\n",
    "y = layers.Input(shape=(num_classes,))\n",
    "masked_by_y = Mask()([digitcaps, y])  # The true label is used to mask the output of capsule layer. For training\n",
    "masked = Mask()(digitcaps)  # Mask using the capsule with maximal length. For prediction\n",
    "\n",
    "# Shared Decoder model in training and prediction\n",
    "decoder = models.Sequential(name='decoder')\n",
    "decoder.add(layers.Dense(512, activation='relu', input_dim=16*num_classes))\n",
    "decoder.add(layers.Dense(1024, activation='relu'))\n",
    "decoder.add(layers.Dense(np.prod(input_shape), activation='sigmoid'))\n",
    "decoder.add(layers.Reshape(target_shape=input_shape, name='out_recon'))\n",
    "\n",
    "# Models for training and evaluation (prediction)\n",
    "model = models.Model([x, y], [out_caps, decoder(masked_by_y)])\n",
    "eval_model = models.Model(x, [out_caps, decoder(masked)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 20, 20, 256)  20992       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "primarycap_conv2d (Conv2D)      (None, 6, 6, 256)    5308672     conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "primarycap_reshape (Reshape)    (None, 1152, 8)      0           primarycap_conv2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "primarycap_squash (Lambda)      (None, 1152, 8)      0           primarycap_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "digitcaps (CapsuleLayer)        (None, 10, 16)       1474560     primarycap_squash[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mask_1 (Mask)                   (None, 160)          0           digitcaps[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "capsnet (Length)                (None, 10)           0           digitcaps[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Sequential)            (None, 28, 28, 1)    1411344     mask_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 8,215,568\n",
      "Trainable params: 8,215,568\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "\n",
    "outpath = \"Capsnet2\"\n",
    "if not os.path.exists(outpath):\n",
    "    os.mkdir(outpath)\n",
    "filepath= outpath + \"/weights-improvement-{epoch:02d}-{val_capsnet_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_capsnet_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def margin_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Margin loss for Eq.(4). When y_true[i, :] contains not just one `1`, this loss should work too. Not test it.\n",
    "    :param y_true: [None, n_classes]\n",
    "    :param y_pred: [None, num_capsule]\n",
    "    :return: a scalar loss value.\n",
    "    \"\"\"\n",
    "    L = y_true * K.square(K.maximum(0., 0.9 - y_pred)) + \\\n",
    "        0.5 * (1 - y_true) * K.square(K.maximum(0., y_pred - 0.1))\n",
    "\n",
    "    return K.mean(K.sum(L, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/15\n",
      "48000/48000 [==============================] - 216s 4ms/step - loss: 0.0522 - capsnet_loss: 0.0446 - decoder_loss: 0.0194 - capsnet_acc: 0.9429 - val_loss: 0.0723 - val_capsnet_loss: 0.0644 - val_decoder_loss: 0.0203 - val_capsnet_acc: 0.9097\n",
      "\n",
      "Epoch 00001: val_capsnet_acc improved from -inf to 0.90967, saving model to Capsnet3/weights-improvement-01-0.91.hdf5\n",
      "Epoch 2/15\n",
      "48000/48000 [==============================] - 214s 4ms/step - loss: 0.0479 - capsnet_loss: 0.0405 - decoder_loss: 0.0190 - capsnet_acc: 0.9483 - val_loss: 0.0716 - val_capsnet_loss: 0.0637 - val_decoder_loss: 0.0200 - val_capsnet_acc: 0.9111\n",
      "\n",
      "Epoch 00002: val_capsnet_acc improved from 0.90967 to 0.91108, saving model to Capsnet3/weights-improvement-02-0.91.hdf5\n",
      "Epoch 3/15\n",
      "48000/48000 [==============================] - 215s 4ms/step - loss: 0.0451 - capsnet_loss: 0.0378 - decoder_loss: 0.0188 - capsnet_acc: 0.9528 - val_loss: 0.0705 - val_capsnet_loss: 0.0627 - val_decoder_loss: 0.0199 - val_capsnet_acc: 0.9134\n",
      "\n",
      "Epoch 00003: val_capsnet_acc improved from 0.91108 to 0.91342, saving model to Capsnet3/weights-improvement-03-0.91.hdf5\n",
      "Epoch 4/15\n",
      "48000/48000 [==============================] - 215s 4ms/step - loss: 0.0432 - capsnet_loss: 0.0359 - decoder_loss: 0.0186 - capsnet_acc: 0.9546 - val_loss: 0.0709 - val_capsnet_loss: 0.0631 - val_decoder_loss: 0.0199 - val_capsnet_acc: 0.9133\n",
      "\n",
      "Epoch 00004: val_capsnet_acc did not improve\n",
      "Epoch 5/15\n",
      "48000/48000 [==============================] - 215s 4ms/step - loss: 0.0411 - capsnet_loss: 0.0339 - decoder_loss: 0.0185 - capsnet_acc: 0.9588 - val_loss: 0.0704 - val_capsnet_loss: 0.0627 - val_decoder_loss: 0.0198 - val_capsnet_acc: 0.9129\n",
      "\n",
      "Epoch 00005: val_capsnet_acc did not improve\n",
      "Epoch 6/15\n",
      " 4000/48000 [=>............................] - ETA: 3:05 - loss: 0.0377 - capsnet_loss: 0.0306 - decoder_loss: 0.0183 - capsnet_acc: 0.9645"
     ]
    }
   ],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer=optimizers.Adam(lr=0.0001),\n",
    "              loss=[margin_loss, 'mse'],\n",
    "              loss_weights=[1., 0.392],\n",
    "              metrics={'capsnet': 'accuracy'})\n",
    "\n",
    "# load saved weights\n",
    "# model.load_weights(\"Capsnet/weights-improvement-10-0.90.hdf5\")\n",
    "\n",
    "# Train\n",
    "history = model.fit([X_train, y_train], [y_train, X_train], batch_size=batch_size, epochs=epochs,\n",
    "          verbose=1, validation_data=[[X_val, y_val], [y_val, X_val]], callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capsnet2/weights-improvement-10-0.91.hdf5\n",
      "--------------------------------------------------\n",
      "Test acc: 0.9182\n",
      "Capsnet2/weights-improvement-12-0.91.hdf5\n",
      "--------------------------------------------------\n",
      "Test acc: 0.9173\n",
      "Capsnet2/weights-improvement-03-0.91.hdf5\n",
      "--------------------------------------------------\n",
      "Test acc: 0.9162\n",
      "Capsnet2/weights-improvement-04-0.91.hdf5\n",
      "--------------------------------------------------\n",
      "Test acc: 0.9144\n",
      "Capsnet2/weights-improvement-05-0.91.hdf5\n",
      "--------------------------------------------------\n",
      "Test acc: 0.9168\n",
      "Capsnet2/weights-improvement-02-0.91.hdf5\n",
      "--------------------------------------------------\n",
      "Test acc: 0.9169\n",
      "Capsnet2/weights-improvement-01-0.91.hdf5\n",
      "--------------------------------------------------\n",
      "Test acc: 0.9146\n",
      "Capsnet2/weights-improvement-09-0.91.hdf5\n",
      "--------------------------------------------------\n",
      "Test acc: 0.9168\n",
      "Capsnet2/weights-improvement-01-0.90.hdf5\n",
      "--------------------------------------------------\n",
      "Test acc: 0.9097\n"
     ]
    }
   ],
   "source": [
    "# weights\n",
    "from glob import glob\n",
    "g = glob(outpath+'/*.hdf5')\n",
    "\n",
    "for wt in g:\n",
    "    model.load_weights(wt)\n",
    "    y_pred, x_recon = eval_model.predict(X_test, batch_size=batch_size)\n",
    "    print(wt)\n",
    "    print('-'*50)\n",
    "    print('Test acc:', np.sum(np.argmax(y_pred, 1) == np.argmax(y_test, 1))/y_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python tf15",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
