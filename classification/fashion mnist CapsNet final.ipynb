{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "dec05004-ccb3-490e-b588-27c0f4f06d1e",
    "_uuid": "41907ec74cae883fa8d56f6556cade5c67c8f3e0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lam/anaconda2/envs/tf15/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train = pd.read_csv('input/fashion-mnist_train.csv')\n",
    "data_test = pd.read_csv('input/fashion-mnist_test.csv')\n",
    "\n",
    "batch_size = 100\n",
    "num_classes = 10\n",
    "epochs = 40\n",
    "\n",
    "img_rows, img_cols = 28, 28\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "X = np.array(data_train.iloc[:, 1:])\n",
    "y = to_categorical(np.array(data_train.iloc[:, 0]))\n",
    "\n",
    "#Here we split validation data to optimiza classifier during training\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=13)\n",
    "\n",
    "#Test data\n",
    "X_test = np.array(data_test.iloc[:, 1:])\n",
    "y_test = to_categorical(np.array(data_test.iloc[:, 0]))\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "X_val = X_val.reshape(X_val.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_val = X_val.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "X_val /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imgaug import augmenters as iaa\n",
    "\n",
    "sometimes = lambda aug: iaa.Sometimes(0.5, aug)\n",
    "# seq = iaa.Sequential([iaa.Fliplr(0.5), sometimes(iaa.Affine(rotate=(-5, 5), shear=(-5, 5)))])\n",
    "seq = iaa.Sequential([iaa.Fliplr(0.5)])\n",
    "X_train = seq.augment_images(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "0599166d-b975-4c88-8b91-071a8f4fb0cd",
    "_uuid": "0e9db73157e2c0e481bf3d73892d8d29263aa56f",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras import layers, models, optimizers\n",
    "from keras import backend as K\n",
    "from capsulelayers import CapsuleLayer, PrimaryCap, Length, Mask\n",
    "\n",
    "K.set_image_data_format('channels_last')\n",
    "\n",
    "x = layers.Input(shape=input_shape)\n",
    "\n",
    "# Layer 1: Just a conventional Conv2D layer\n",
    "conv1 = layers.Conv2D(filters=256, kernel_size=9, strides=1, padding='valid', activation='relu', name='conv1')(x)\n",
    "\n",
    "# Layer 2: Conv2D layer with `squash` activation, then reshape to [None, num_capsule, dim_capsule]\n",
    "primarycaps = PrimaryCap(conv1, dim_capsule=8, n_channels=32, kernel_size=9, strides=2, padding='valid')\n",
    "\n",
    "# Layer 3: Capsule layer. Routing algorithm works here.\n",
    "digitcaps = CapsuleLayer(num_capsule=num_classes, dim_capsule=16, num_routing=3,\n",
    "                         name='digitcaps')(primarycaps)\n",
    "\n",
    "# Layer 4: This is an auxiliary layer to replace each capsule with its length. Just to match the true label's shape.\n",
    "# If using tensorflow, this will not be necessary. :)\n",
    "out_caps = Length(name='capsnet')(digitcaps)\n",
    "\n",
    "# Decoder network.\n",
    "y = layers.Input(shape=(num_classes,))\n",
    "masked_by_y = Mask()([digitcaps, y])  # The true label is used to mask the output of capsule layer. For training\n",
    "masked = Mask()(digitcaps)  # Mask using the capsule with maximal length. For prediction\n",
    "\n",
    "# Shared Decoder model in training and prediction\n",
    "decoder = models.Sequential(name='decoder')\n",
    "decoder.add(layers.Dense(512, activation='relu', input_dim=16*num_classes))\n",
    "decoder.add(layers.Dense(1024, activation='relu'))\n",
    "decoder.add(layers.Dense(np.prod(input_shape), activation='sigmoid'))\n",
    "decoder.add(layers.Reshape(target_shape=input_shape, name='out_recon'))\n",
    "\n",
    "# Models for training and evaluation (prediction)\n",
    "model = models.Model([x, y], [out_caps, decoder(masked_by_y)])\n",
    "eval_model = models.Model(x, [out_caps, decoder(masked)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 20, 20, 256)  20992       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "primarycap_conv2d (Conv2D)      (None, 6, 6, 256)    5308672     conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "primarycap_reshape (Reshape)    (None, 1152, 8)      0           primarycap_conv2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "primarycap_squash (Lambda)      (None, 1152, 8)      0           primarycap_reshape[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "digitcaps (CapsuleLayer)        (None, 10, 16)       1474560     primarycap_squash[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 10)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "mask_1 (Mask)                   (None, 160)          0           digitcaps[0][0]                  \n",
      "                                                                 input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "capsnet (Length)                (None, 10)           0           digitcaps[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Sequential)            (None, 28, 28, 1)    1411344     mask_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 8,215,568\n",
      "Trainable params: 8,215,568\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "import os\n",
    "\n",
    "outpath = \"Capsnet2\"\n",
    "if not os.path.exists(outpath):\n",
    "    os.mkdir(outpath)\n",
    "filepath= outpath + \"/weights-improvement-{epoch:02d}-{val_capsnet_acc:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_capsnet_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def margin_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Margin loss for Eq.(4). When y_true[i, :] contains not just one `1`, this loss should work too. Not test it.\n",
    "    :param y_true: [None, n_classes]\n",
    "    :param y_pred: [None, num_capsule]\n",
    "    :return: a scalar loss value.\n",
    "    \"\"\"\n",
    "    L = y_true * K.square(K.maximum(0., 0.9 - y_pred)) + \\\n",
    "        0.5 * (1 - y_true) * K.square(K.maximum(0., y_pred - 0.1))\n",
    "\n",
    "    return K.mean(K.sum(L, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/40\n",
      "48000/48000 [==============================] - 215s 4ms/step - loss: 0.0389 - capsnet_loss: 0.0314 - decoder_loss: 0.0191 - capsnet_acc: 0.9619 - val_loss: 0.0734 - val_capsnet_loss: 0.0652 - val_decoder_loss: 0.0207 - val_capsnet_acc: 0.9116\n",
      "\n",
      "Epoch 00001: val_capsnet_acc improved from -inf to 0.91158, saving model to Capsnet/weights-improvement-01-0.91.hdf5\n",
      "Epoch 2/40\n",
      "48000/48000 [==============================] - 214s 4ms/step - loss: 0.0357 - capsnet_loss: 0.0283 - decoder_loss: 0.0187 - capsnet_acc: 0.9658 - val_loss: 0.0730 - val_capsnet_loss: 0.0649 - val_decoder_loss: 0.0205 - val_capsnet_acc: 0.9118\n",
      "\n",
      "Epoch 00002: val_capsnet_acc improved from 0.91158 to 0.91183, saving model to Capsnet/weights-improvement-02-0.91.hdf5\n",
      "Epoch 3/40\n",
      "48000/48000 [==============================] - 215s 4ms/step - loss: 0.0338 - capsnet_loss: 0.0266 - decoder_loss: 0.0185 - capsnet_acc: 0.9681 - val_loss: 0.0730 - val_capsnet_loss: 0.0650 - val_decoder_loss: 0.0203 - val_capsnet_acc: 0.9130\n",
      "\n",
      "Epoch 00003: val_capsnet_acc improved from 0.91183 to 0.91300, saving model to Capsnet/weights-improvement-03-0.91.hdf5\n",
      "Epoch 4/40\n",
      "48000/48000 [==============================] - 215s 4ms/step - loss: 0.0324 - capsnet_loss: 0.0252 - decoder_loss: 0.0184 - capsnet_acc: 0.9698 - val_loss: 0.0731 - val_capsnet_loss: 0.0651 - val_decoder_loss: 0.0203 - val_capsnet_acc: 0.9094\n",
      "\n",
      "Epoch 00004: val_capsnet_acc did not improve\n",
      "Epoch 5/40\n",
      "48000/48000 [==============================] - 215s 4ms/step - loss: 0.0311 - capsnet_loss: 0.0239 - decoder_loss: 0.0182 - capsnet_acc: 0.9720 - val_loss: 0.0739 - val_capsnet_loss: 0.0660 - val_decoder_loss: 0.0201 - val_capsnet_acc: 0.9103\n",
      "\n",
      "Epoch 00005: val_capsnet_acc did not improve\n",
      "Epoch 6/40\n",
      "48000/48000 [==============================] - 215s 4ms/step - loss: 0.0299 - capsnet_loss: 0.0228 - decoder_loss: 0.0181 - capsnet_acc: 0.9732 - val_loss: 0.0732 - val_capsnet_loss: 0.0654 - val_decoder_loss: 0.0200 - val_capsnet_acc: 0.9111\n",
      "\n",
      "Epoch 00006: val_capsnet_acc did not improve\n",
      "Epoch 7/40\n",
      "48000/48000 [==============================] - 215s 4ms/step - loss: 0.0287 - capsnet_loss: 0.0216 - decoder_loss: 0.0179 - capsnet_acc: 0.9755 - val_loss: 0.0734 - val_capsnet_loss: 0.0656 - val_decoder_loss: 0.0200 - val_capsnet_acc: 0.9121\n",
      "\n",
      "Epoch 00007: val_capsnet_acc did not improve\n",
      "Epoch 8/40\n",
      "48000/48000 [==============================] - 215s 4ms/step - loss: 0.0275 - capsnet_loss: 0.0205 - decoder_loss: 0.0178 - capsnet_acc: 0.9761 - val_loss: 0.0748 - val_capsnet_loss: 0.0670 - val_decoder_loss: 0.0198 - val_capsnet_acc: 0.9098\n",
      "\n",
      "Epoch 00008: val_capsnet_acc did not improve\n",
      "Epoch 9/40\n",
      "48000/48000 [==============================] - 215s 4ms/step - loss: 0.0265 - capsnet_loss: 0.0195 - decoder_loss: 0.0177 - capsnet_acc: 0.9774 - val_loss: 0.0741 - val_capsnet_loss: 0.0664 - val_decoder_loss: 0.0198 - val_capsnet_acc: 0.9109\n",
      "\n",
      "Epoch 00009: val_capsnet_acc did not improve\n",
      "Epoch 10/40\n",
      "48000/48000 [==============================] - 215s 4ms/step - loss: 0.0253 - capsnet_loss: 0.0184 - decoder_loss: 0.0175 - capsnet_acc: 0.9794 - val_loss: 0.0751 - val_capsnet_loss: 0.0673 - val_decoder_loss: 0.0198 - val_capsnet_acc: 0.9090\n",
      "\n",
      "Epoch 00010: val_capsnet_acc did not improve\n",
      "Epoch 11/40\n",
      "48000/48000 [==============================] - 215s 4ms/step - loss: 0.0244 - capsnet_loss: 0.0176 - decoder_loss: 0.0174 - capsnet_acc: 0.9805 - val_loss: 0.0752 - val_capsnet_loss: 0.0674 - val_decoder_loss: 0.0198 - val_capsnet_acc: 0.9113\n",
      "\n",
      "Epoch 00011: val_capsnet_acc did not improve\n",
      "Epoch 12/40\n",
      "48000/48000 [==============================] - 215s 4ms/step - loss: 0.0233 - capsnet_loss: 0.0165 - decoder_loss: 0.0173 - capsnet_acc: 0.9819 - val_loss: 0.0748 - val_capsnet_loss: 0.0671 - val_decoder_loss: 0.0197 - val_capsnet_acc: 0.9108\n",
      "\n",
      "Epoch 00012: val_capsnet_acc did not improve\n",
      "Epoch 13/40\n",
      "48000/48000 [==============================] - 215s 4ms/step - loss: 0.0225 - capsnet_loss: 0.0157 - decoder_loss: 0.0172 - capsnet_acc: 0.9828 - val_loss: 0.0753 - val_capsnet_loss: 0.0677 - val_decoder_loss: 0.0195 - val_capsnet_acc: 0.9116\n",
      "\n",
      "Epoch 00013: val_capsnet_acc did not improve\n",
      "Epoch 14/40\n",
      "48000/48000 [==============================] - 215s 4ms/step - loss: 0.0216 - capsnet_loss: 0.0149 - decoder_loss: 0.0171 - capsnet_acc: 0.9838 - val_loss: 0.0750 - val_capsnet_loss: 0.0674 - val_decoder_loss: 0.0194 - val_capsnet_acc: 0.9108\n",
      "\n",
      "Epoch 00014: val_capsnet_acc did not improve\n",
      "Epoch 15/40\n",
      "48000/48000 [==============================] - 215s 4ms/step - loss: 0.0206 - capsnet_loss: 0.0139 - decoder_loss: 0.0169 - capsnet_acc: 0.9855 - val_loss: 0.0763 - val_capsnet_loss: 0.0687 - val_decoder_loss: 0.0194 - val_capsnet_acc: 0.9079\n",
      "\n",
      "Epoch 00015: val_capsnet_acc did not improve\n",
      "Epoch 16/40\n",
      "48000/48000 [==============================] - 215s 4ms/step - loss: 0.0199 - capsnet_loss: 0.0133 - decoder_loss: 0.0168 - capsnet_acc: 0.9859 - val_loss: 0.0764 - val_capsnet_loss: 0.0688 - val_decoder_loss: 0.0194 - val_capsnet_acc: 0.9125\n",
      "\n",
      "Epoch 00016: val_capsnet_acc did not improve\n",
      "Epoch 17/40\n",
      "48000/48000 [==============================] - 215s 4ms/step - loss: 0.0191 - capsnet_loss: 0.0125 - decoder_loss: 0.0167 - capsnet_acc: 0.9869 - val_loss: 0.0771 - val_capsnet_loss: 0.0695 - val_decoder_loss: 0.0193 - val_capsnet_acc: 0.9093\n",
      "\n",
      "Epoch 00017: val_capsnet_acc did not improve\n",
      "Epoch 18/40\n",
      "48000/48000 [==============================] - 215s 4ms/step - loss: 0.0182 - capsnet_loss: 0.0117 - decoder_loss: 0.0166 - capsnet_acc: 0.9879 - val_loss: 0.0764 - val_capsnet_loss: 0.0688 - val_decoder_loss: 0.0193 - val_capsnet_acc: 0.9115\n",
      "\n",
      "Epoch 00018: val_capsnet_acc did not improve\n",
      "Epoch 19/40\n",
      "48000/48000 [==============================] - 215s 4ms/step - loss: 0.0175 - capsnet_loss: 0.0111 - decoder_loss: 0.0165 - capsnet_acc: 0.9888 - val_loss: 0.0772 - val_capsnet_loss: 0.0697 - val_decoder_loss: 0.0192 - val_capsnet_acc: 0.9083\n",
      "\n",
      "Epoch 00019: val_capsnet_acc did not improve\n",
      "Epoch 20/40\n",
      "48000/48000 [==============================] - 215s 4ms/step - loss: 0.0169 - capsnet_loss: 0.0105 - decoder_loss: 0.0164 - capsnet_acc: 0.9897 - val_loss: 0.0794 - val_capsnet_loss: 0.0718 - val_decoder_loss: 0.0192 - val_capsnet_acc: 0.9068\n",
      "\n",
      "Epoch 00020: val_capsnet_acc did not improve\n",
      "Epoch 21/40\n",
      "48000/48000 [==============================] - 215s 4ms/step - loss: 0.0162 - capsnet_loss: 0.0098 - decoder_loss: 0.0163 - capsnet_acc: 0.9906 - val_loss: 0.0788 - val_capsnet_loss: 0.0713 - val_decoder_loss: 0.0191 - val_capsnet_acc: 0.9093\n",
      "\n",
      "Epoch 00021: val_capsnet_acc did not improve\n",
      "Epoch 22/40\n",
      "48000/48000 [==============================] - 215s 4ms/step - loss: 0.0154 - capsnet_loss: 0.0091 - decoder_loss: 0.0162 - capsnet_acc: 0.9911 - val_loss: 0.0786 - val_capsnet_loss: 0.0712 - val_decoder_loss: 0.0190 - val_capsnet_acc: 0.9081\n",
      "\n",
      "Epoch 00022: val_capsnet_acc did not improve\n",
      "Epoch 23/40\n",
      "48000/48000 [==============================] - 215s 4ms/step - loss: 0.0148 - capsnet_loss: 0.0085 - decoder_loss: 0.0161 - capsnet_acc: 0.9919 - val_loss: 0.0781 - val_capsnet_loss: 0.0708 - val_decoder_loss: 0.0188 - val_capsnet_acc: 0.9088\n",
      "\n",
      "Epoch 00023: val_capsnet_acc did not improve\n",
      "Epoch 24/40\n",
      "48000/48000 [==============================] - 215s 4ms/step - loss: 0.0143 - capsnet_loss: 0.0080 - decoder_loss: 0.0160 - capsnet_acc: 0.9925 - val_loss: 0.0800 - val_capsnet_loss: 0.0726 - val_decoder_loss: 0.0189 - val_capsnet_acc: 0.9082\n",
      "\n",
      "Epoch 00024: val_capsnet_acc did not improve\n",
      "Epoch 25/40\n",
      "48000/48000 [==============================] - 215s 4ms/step - loss: 0.0137 - capsnet_loss: 0.0075 - decoder_loss: 0.0158 - capsnet_acc: 0.9931 - val_loss: 0.0788 - val_capsnet_loss: 0.0714 - val_decoder_loss: 0.0187 - val_capsnet_acc: 0.9093\n",
      "\n",
      "Epoch 00025: val_capsnet_acc did not improve\n",
      "Epoch 26/40\n",
      "48000/48000 [==============================] - 215s 4ms/step - loss: 0.0132 - capsnet_loss: 0.0070 - decoder_loss: 0.0157 - capsnet_acc: 0.9934 - val_loss: 0.0803 - val_capsnet_loss: 0.0729 - val_decoder_loss: 0.0187 - val_capsnet_acc: 0.9081\n",
      "\n",
      "Epoch 00026: val_capsnet_acc did not improve\n",
      "Epoch 27/40\n",
      "48000/48000 [==============================] - 214s 4ms/step - loss: 0.0127 - capsnet_loss: 0.0066 - decoder_loss: 0.0156 - capsnet_acc: 0.9941 - val_loss: 0.0799 - val_capsnet_loss: 0.0726 - val_decoder_loss: 0.0187 - val_capsnet_acc: 0.9079\n",
      "\n",
      "Epoch 00027: val_capsnet_acc did not improve\n",
      "Epoch 28/40\n",
      "48000/48000 [==============================] - 214s 4ms/step - loss: 0.0123 - capsnet_loss: 0.0062 - decoder_loss: 0.0155 - capsnet_acc: 0.9945 - val_loss: 0.0788 - val_capsnet_loss: 0.0715 - val_decoder_loss: 0.0186 - val_capsnet_acc: 0.9092\n",
      "\n",
      "Epoch 00028: val_capsnet_acc did not improve\n",
      "Epoch 29/40\n",
      "18900/48000 [==========>...................] - ETA: 2:01 - loss: 0.0116 - capsnet_loss: 0.0055 - decoder_loss: 0.0154 - capsnet_acc: 0.9949"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-1e44b13ac6c8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m history = model.fit([X_train, y_train], [y_train, X_train], batch_size=batch_size, epochs=epochs,\n\u001b[0;32m---> 11\u001b[0;31m           verbose=1, validation_data=[[X_val, y_val], [y_val, X_val]], callbacks=callbacks_list)\n\u001b[0m",
      "\u001b[0;32m~/anaconda2/envs/tf15/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda2/envs/tf15/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1235\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1236\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tf15/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2478\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2479\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tf15/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tf15/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tf15/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tf15/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1325\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda2/envs/tf15/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1300\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# compile the model\n",
    "model.compile(optimizer=optimizers.Adam(lr=0.0001),\n",
    "              loss=[margin_loss, 'mse'],\n",
    "              loss_weights=[1., 0.392],\n",
    "              metrics={'capsnet': 'accuracy'})\n",
    "\n",
    "model.load_weights(outpath+\"/weights-improvement-10-0.90.hdf5\")\n",
    "\n",
    "# Train\n",
    "history = model.fit([X_train, y_train], [y_train, X_train], batch_size=batch_size, epochs=epochs,\n",
    "          verbose=1, validation_data=[[X_val, y_val], [y_val, X_val]], callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capsnet2/weights-improvement-10-0.91.hdf5\n",
      "--------------------------------------------------\n",
      "Test acc: 0.9182\n",
      "Capsnet2/weights-improvement-12-0.91.hdf5\n",
      "--------------------------------------------------\n",
      "Test acc: 0.9173\n",
      "Capsnet2/weights-improvement-03-0.91.hdf5\n",
      "--------------------------------------------------\n",
      "Test acc: 0.9162\n",
      "Capsnet2/weights-improvement-04-0.91.hdf5\n",
      "--------------------------------------------------\n",
      "Test acc: 0.9144\n",
      "Capsnet2/weights-improvement-05-0.91.hdf5\n",
      "--------------------------------------------------\n",
      "Test acc: 0.9168\n",
      "Capsnet2/weights-improvement-02-0.91.hdf5\n",
      "--------------------------------------------------\n",
      "Test acc: 0.9169\n",
      "Capsnet2/weights-improvement-01-0.91.hdf5\n",
      "--------------------------------------------------\n",
      "Test acc: 0.9146\n",
      "Capsnet2/weights-improvement-09-0.91.hdf5\n",
      "--------------------------------------------------\n",
      "Test acc: 0.9168\n",
      "Capsnet2/weights-improvement-01-0.90.hdf5\n",
      "--------------------------------------------------\n",
      "Test acc: 0.9097\n"
     ]
    }
   ],
   "source": [
    "# weights\n",
    "from glob import glob\n",
    "g = glob(outpath + '/*.hdf5')\n",
    "\n",
    "for wt in g:\n",
    "    model.load_weights(wt)\n",
    "    y_pred, x_recon = eval_model.predict(X_test, batch_size=batch_size)\n",
    "    print(wt)\n",
    "    print('-'*50)\n",
    "    print('Test acc:', np.sum(np.argmax(y_pred, 1) == np.argmax(y_test, 1))/y_test.shape[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python tf15",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
