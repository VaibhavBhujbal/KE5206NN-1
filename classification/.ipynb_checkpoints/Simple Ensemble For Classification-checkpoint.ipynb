{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An ensemble of Neural networks to classify the Fashion MNIST images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pier/anaconda3/envs/tensorflow/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the fasion MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training and testing data\n",
    "(X_train, Y_train), (X_test, Y_test) = fashion_mnist.load_data()\n",
    "# Display purpose:\n",
    "X_train_orig = X_train\n",
    "X_test_orig = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    shape_ord = (1, img_rows, img_cols)\n",
    "else:  # channel_last\n",
    "    shape_ord = (img_rows, img_cols, 1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape((X_train.shape[0],) + shape_ord)\n",
    "X_test = X_test.reshape((X_test.shape[0],) + shape_ord)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the NN models that are already trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = load_model('cnn.h5')\n",
    "mlff_bp_model = load_model('mlff_bp_model.h5')\n",
    "rnn_bi_gru_model = load_model('bidirectional_gru.h5')\n",
    "rnn_bi_gru_model.name = \"rnn\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification_accuracy_ensemble(models_with_accuracy, test_images, test_labels):\n",
    "    \"\"\"\n",
    "    Get the classification accuracy of the models in the ensemble\n",
    "    \"\"\"\n",
    "    models_with_accuracy = [(model, accuracy * 100) for (model, accuracy) in models_with_accuracy if accuracy <= 1]\n",
    "    \n",
    "    num_test_images = len(test_images)\n",
    "    num_test_labels = len(test_labels)\n",
    "    \n",
    "    if num_test_images != num_test_labels:\n",
    "        raise ValueError(\"The number of test images does not equal the number of test labels.\")\n",
    "\n",
    "    prediction_results = []\n",
    "    for model, accuracy in models_with_accuracy:\n",
    "        # print(\"Accuracy: \" + str(accuracy))\n",
    "        \n",
    "        # Get arrays (of size 10) of predictions for each test image\n",
    "        if model.name==\"rnn\":\n",
    "            original_predictions = model.predict(np.squeeze(test_images)) # rnn doesn't take in dimension of 1 \n",
    "        else:\n",
    "            original_predictions = model.predict(test_images)\n",
    "        # print(original_predictions)\n",
    "        \n",
    "        # multiply each element of predictions for each test image with the accuracy\n",
    "        weighted_predictions = [accuracy * predictions_for_test_image for predictions_for_test_image in original_predictions]\n",
    "        # print(\"Weighted predictions...\")\n",
    "        # print(weighted_predictions)\n",
    "        prediction_results.append(weighted_predictions)\n",
    "        \n",
    "    ensembles_predictions = []\n",
    "    for itr in range(num_test_images):\n",
    "        prediction_sum = np.asarray([0.0]*10)\n",
    "        for prediction_result in prediction_results:\n",
    "            prediction_sum += (prediction_result[itr])\n",
    "        # print(prediction_sum)\n",
    "        ensembles_predictions.append(prediction_sum.argmax(-1))\n",
    "        \n",
    "    correct_classifications = 0\n",
    "    for idx, prediction in enumerate(ensembles_predictions):\n",
    "        if prediction == test_labels[idx]:\n",
    "            correct_classifications += 1\n",
    "            \n",
    "    print(\"{0} classified correctly out of {1}. Classification accuracy: {2}\".format(correct_classifications, str(num_test_images), correct_classifications/num_test_images))\n",
    "    return ensembles_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the classification accuracy of the ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9088 classified correctly out of 10000. Classification accuracy: 0.9088\n"
     ]
    }
   ],
   "source": [
    "slice = 10000\n",
    "models_with_accuracy = [(cnn_model, 0.9), (rnn_bi_gru_model, 0.89), (mlff_bp_model, 0.88)]\n",
    "test_data = X_test[:slice]\n",
    "test_labels = Y_test[:slice]\n",
    "\n",
    "ensemble_predictions = get_classification_accuracy_ensemble(models_with_accuracy, test_data, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate the confusion matrix for the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T-shirt/Top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle Boot']\n",
      "Actuals ->\n",
      "[[880   0  14  21   2   1  73   0   9   0]\n",
      " [  1 971   0  23   2   0   2   0   1   0]\n",
      " [ 14   0 859  13  67   0  46   0   1   0]\n",
      " [ 17   2   8 934  20   0  14   0   5   0]\n",
      " [  1   1  64  34 846   0  53   0   1   0]\n",
      " [  0   0   0   0   0 981   0  14   1   4]\n",
      " [125   2  69  26  54   0 712   0  12   0]\n",
      " [  0   0   0   0   0  10   0 981   0   9]\n",
      " [  1   1   2   5   2   3   0   3 983   0]\n",
      " [  1   0   0   0   0   6   0  52   0 941]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "item_label_mapping = [\"T-shirt/Top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\", \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle Boot\"]\n",
    "\n",
    "print(item_label_mapping)\n",
    "print(\"Actuals ->\")\n",
    "c = confusion_matrix(Y_test, ensemble_predictions)\n",
    "\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
