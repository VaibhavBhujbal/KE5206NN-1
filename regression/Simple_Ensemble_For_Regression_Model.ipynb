{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Simple Ensemble For Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training shapes\n",
      "(27750, 27)\n",
      "(27750,)\n",
      "Testing shapes\n",
      "(11894, 27)\n",
      "(11894,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pierlim/anaconda/envs/tensorflow/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/pierlim/anaconda/envs/tensorflow/lib/python3.6/site-packages/pandas/core/indexing.py:537: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from neupy import environment\n",
    "from sklearn.model_selection import train_test_split\n",
    "from neupy import environment\n",
    "from operator import itemgetter\n",
    "import numpy as np\n",
    "from neupy import algorithms, layers, estimators\n",
    "from sklearn import datasets, grid_search\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "def scorer(actual, predicted):\n",
    "    return estimators.rmse(predicted, actual)\n",
    "\n",
    "training_df = pd.read_csv(\n",
    "    \"data_with_fields_removed/train_70.0_updated.csv\")\n",
    "training_X = training_df.loc[:, training_df.columns != \" shares\"]\n",
    "training_Y = training_df.loc[:, \" shares\"]\n",
    "\n",
    "test_df = pd.read_csv(\n",
    "    \"data_with_fields_removed/test_30.0_updated.csv\")\n",
    "testing_X = test_df.loc[:, test_df.columns != \" shares\"]\n",
    "testing_Y = test_df.loc[:, \" shares\"]\n",
    "\n",
    "print(\"Training shapes\")\n",
    "print(training_X.shape)\n",
    "print(training_Y.shape)\n",
    "\n",
    "print(\"Testing shapes\")\n",
    "print(testing_X.shape)\n",
    "print(testing_Y.shape)\n",
    "\n",
    "x_data_scaler = preprocessing.MinMaxScaler()\n",
    "y_data_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "columns_to_scale = [\" n_tokens_title\", \" n_tokens_content\", \" num_hrefs\", \" num_self_hrefs\", \" num_imgs\", \" num_videos\", \" average_token_length\", \" num_keywords\", \" kw_avg_min\",\" kw_avg_max\", \" kw_avg_avg\",\" self_reference_avg_sharess\"]\n",
    "\n",
    "x_data_scaler.fit(training_X.loc[:, columns_to_scale])\n",
    "y_data_scaler.fit(training_Y.values.reshape(-1, 1))\n",
    "\n",
    "training_X.loc[:, columns_to_scale] = x_data_scaler.transform(training_X.loc[:, columns_to_scale])\n",
    "training_Y = y_data_scaler.transform(training_Y.values.reshape(-1, 1))\n",
    "\n",
    "testing_X.loc[:, columns_to_scale] = x_data_scaler.transform(testing_X.loc[:, columns_to_scale])\n",
    "testing_Y = y_data_scaler.transform(testing_Y.values.reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Pre-Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from scipy import stats\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "from neupy import estimators\n",
    "import _pickle\n",
    "\n",
    "with open('regression_models/multi_layer_perceptron.pkl', 'rb') as fid:\n",
    "    mlp = _pickle.load(fid)\n",
    "\n",
    "with open('regression_models/grnn.pkl', 'rb') as fid:\n",
    "    grnn = _pickle.load(fid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPRegressor(activation='tanh', alpha=0.215, batch_size='auto', beta_1=0.5,\n",
      "       beta_2=0.76, early_stopping=True, epsilon=1e-08,\n",
      "       hidden_layer_sizes=(1000, 100, 100), learning_rate='constant',\n",
      "       learning_rate_init=0.0218, max_iter=2000, momentum=0.9,\n",
      "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
      "       shuffle=True, solver='sgd', tol=0.0001, validation_fraction=0.1,\n",
      "       verbose=False, warm_start=False)\n",
      "GRNN(verbose=True, step=None, show_epoch=None, shuffle_data=None, epoch_end_signal=None, train_end_signal=None, std=0.2)\n",
      "Ensemble MAE = 0.003985574610490937\n",
      "Ensemble MAE (no. of shares) = 2752.636725508333\n"
     ]
    }
   ],
   "source": [
    "models = [mlp, grnn]\n",
    "y_ensemble_predicted = np.zeros(shape=(testing_X.shape[0], 1))\n",
    "denom = 0\n",
    "\n",
    "for model in models:\n",
    "    print(model)\n",
    "    y_predicted = model.predict(testing_X)\n",
    "    if model.__class__ == grnn.__class__: # take care of neupy diff format\n",
    "        y_predicted = y_predicted.ravel().transpose()\n",
    "    mae = estimators.mae(y_predicted, testing_Y.ravel())\n",
    "    denom = denom + (1.0 / (1+mae))\n",
    "    y_ensemble_predicted = np.add(y_ensemble_predicted, ((1.0 / (1+mae)) * y_predicted))\n",
    "\n",
    "ensemble_mae = estimators.mae(y_ensemble_predicted, testing_Y.ravel())\n",
    "ensemble_mae = ensemble_mae / denom\n",
    "print(\"Ensemble MAE = \" + str(ensemble_mae))\n",
    "actual_mae = y_data_scaler.inverse_transform(ensemble_mae)\n",
    "print(\"Ensemble MAE (no. of shares) = \" + str(actual_mae.squeeze()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
